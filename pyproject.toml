[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "spectra-db"
version = "0.0.2"
description = "Local-first spectroscopy database + query API backed by DuckDB."
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [{name = "Rees Verleur"}]

dependencies = [
  "duckdb>=0.10",
  "pandas>=2.1",
  "platformdirs>=4.2",
]

[project.optional-dependencies]
# Everything needed to run the scraping/normalization pipeline and its tests.
# Key point: lxml is required for BeautifulSoup("lxml") and (commonly) pandas.read_html parsing.
scrape = [
  "requests>=2.31",
  "beautifulsoup4>=4.12",
  "lxml>=5.0",
  "html5lib>=1.1",
]

# Docs tooling used by the GitHub docs workflow.
docs = [
  "mkdocs>=1.6",
  "mkdocs-material>=9.5",
]

# Dev/CI tooling.
# CI should install: -e ".[dev,scrape]" so tests have parser dependencies.
dev = [
  "pytest>=7.4",
  "ruff>=0.4",
  "types-requests>=2.31",
]

[project.scripts]
spectra-db = "spectra_db.cli:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
include = ["spectra_db*"]

[tool.ruff]
line-length = 200
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP"]
ignore = []

[tool.pytest.ini_options]
testpaths = ["tests"]
